/**
 * Generators
 * 
 * This module accepts a completed `answers` array and processes it to produce
 * the test data sets based on a `colspec`.
 * 
 * @module
 */

import path from 'path'
import { fileURLToPath } from 'url'
import { faker } from '@faker-js/faker'
import { omit } from 'ramda'
import { pascalCase } from 'change-case'
import { getRequiredCols } from './colspecUtilities.mjs'
import {
  transpose,
  convertToCsv,
  mangleColumns,
  mangleColumnNames,
  shuffleColumns,
  removeRandomRows,
} from './generatorUtilities.mjs'

// extract this commonly-used helper function
const { unique } = faker.helpers
// list of props to omit from column specs before value generation
const nonParams = ['name', 'variants', 'cat', 'type', 'unique', 'convert', 'opts']

// Reset the default string representation of a date to the ISO 8601 standard
Date.prototype.toString = Date.prototype.toISOString

/**
 * This is the main test data generation function. It orchestrates all of the test
 * data generation and transformations and returns two 2D arrays, one for `source`
 * and one for `target`, that contain the rows that will be later converted to
 * CSV format for output.
 * 
 * @param   {array}  answers The array of answers to CLI questions
 * @param   {array}  colspec The array of column specifications
 * @returns {object}         A JSON object containing SOURCE and TARGET data arrays
 */
export const generate = (answers, colspec) => {
  const {
    includeOptional,
    sourceCount: rows,
    rowDiff: diff,
    colsRandomized,
    mangleColNames,
    floatColsToTweak,
    dateColsToMangle,
    geoColsToMangle
  } = answers

  /**
   * Remove optional columns from the column specification if
   * these rows are not being generated
   */
  colspec = includeOptional ? colspec : getRequiredCols(colspec)

  /**
   * Generate the base SOURCE table with standard headers, column order
   * and rowCount === max(SOURCE, TARGET) so rows can be removed from one later
   */
  let source = colspec.reduce((src, c, i, cs) => {
    // generate all headers on the first iteration
    if (i === 0) {
      src[0] = generateHeaders(cs, false)
    }
    const params = c.opts ? omit(nonParams, c) : Object.values(omit(nonParams, c))
    const rowCount = diff > 0 ? rows + diff : rows
    src.push(generateValues(c, params, rowCount))
    if (c.convert) {
      src[i+1] = src[i+1].map(Number)
    }
    return src
  }, [])

  /**
   * deep clone SOURCE into TARGET
   */
  let target = JSON.parse(JSON.stringify(source))
  
  /**
   * Apply column transformations
   */
  if (floatColsToTweak && floatColsToTweak[0] !== 'None') {
    target = mangleColumns(target, floatColsToTweak, 'float')
  }
  
  if (dateColsToMangle && dateColsToMangle[0] !== 'None') {
    target = mangleColumns(target, dateColsToMangle, 'date')
  }
  
  if (geoColsToMangle && geoColsToMangle[0] !== 'None') {
    target = mangleColumns(target, geoColsToMangle, 'geo')
  }

  if (mangleColNames && mangleColNames[0] !== 'None') {
    target = mangleColumnNames(target, mangleColNames, colspec)
  }

  /**
   * Randomize column order in TARGET, if requested
   */
  if (colsRandomized) {
    target = shuffleColumns(target)
  }

  /**
   * Transpose 2D arrays from having each row be one column of data,
   * all values having the same data type, to each row being one record
   * as it will appear in the final output tables. Note that the header
   * row is already in the correct format, so is handled differently.
   */
  source = [source[0], ...transpose(source.slice(1))]
  target = [target[0], ...transpose(target.slice(1))]

  /**
   * Randomly remove a specified number of rows from one of the tables
   * to meet the requirements specified by the user
   */
  if (diff > 0) {
    source = removeRandomRows(source, diff)
  } else if (diff < 0) {
    target = removeRandomRows(target, Math.abs(diff))
  }

  return { source, target }
}

/**
 * Takes an object that contains two 2D arrays for the `source` and `target` tables that
 * represents the processed, completed values generated by the CLI tool. Returns the
 * absolute paths to where the `source` and `target` CSV files should be written and also
 * the CSV-formatted string content that should be written to those files.
 * 
 * @param {object} data An object with `source` and `target` props containing table data
 * @returns {object} An object containing absolute paths and CSV-formatted table data
 */
export const generateCsv = data => {
  const __dirname = path.dirname(fileURLToPath(import.meta.url))
  return {
    source: {
      path: `${__dirname.replace('src', 'output')}${path.sep}source_${new Date().getTime()}.csv`,
      content: convertToCsv(data.source),
    },
    target: {
      path: `${__dirname.replace('src', 'output')}${path.sep}target_${new Date().getTime()}.csv`,
      content: convertToCsv(data.target),
    },
  }
}

/**
 * Generates (possibly mangled) headers from a colspec
 * 
 * @param   {array}   colspec The array of column specifications
 * @param   {boolean} mangle  Should colnames be mangled
 * @returns {array}           An array of column headers
 */
const generateHeaders = (colspec, mangle) =>
  colspec.map(cs => mangle ? mangleName(cs.variants) : pascalCase(cs.name))

/**
 * Generate all of the values for given column specification
 * 
 * @param   {object}       col    The column specification from which to generate values
 * @param   {object|array} params The parameters for the Faker function
 * @param   {number}       num    The number of values to generate
 * @returns {array}               An array of randomly generated values
 */
const generateValues = (col, params, num) => {
  const f = faker[col.cat][col.type]
  let gen
  if (col.unique) {
    gen = () => col.opts ? unique(() => f(params)) : unique(() => f(...params))
  } else {
    gen = () => col.opts ? f(params) : f(...params)
  }
  let output
  try {
    output = Array.from({ length: num }).map(gen)
  } catch (e) {
    console.log('generateValues failed:', col, params, num)
    console.log(e)
  }
  return output
}
